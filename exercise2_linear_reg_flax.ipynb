{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5lAxbrS145P"
   },
   "source": [
    "### Exercise 2: Linear Regression in Flax\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/rastringer/jax_notebooks/blob/master/exercise2_linear_reg_flax.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3269,
     "status": "ok",
     "timestamp": 1685486924860,
     "user": {
      "displayName": "Robin Stringer",
      "userId": "05796722230835218202"
     },
     "user_tz": -60
    },
    "id": "jaAZzJrN1_2p",
    "outputId": "f36117e5-a194-49d6-cad4-bac232275010"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp, random, lax, jit\n",
    "from flax import linen as nn\n",
    "\n",
    "# TODO: Data preparation\n",
    "# Create variables X and Y:\n",
    "# X is a 1 x 10 matrix\n",
    "# Y is a 1-dimensional array of size 5\n",
    "# Some references on generating matrices here:\n",
    "# https://flax.readthedocs.io/en/latest/guides/jax_for_the_impatient.html\n",
    "\n",
    "X = pass\n",
    "Y = pass\n",
    "\n",
    "# TODO: create a model of one Dense layer with 5 features \n",
    "# For help:\n",
    "# https://flax.readthedocs.io/en/latest/guides/flax_basics.html\n",
    "model = nn.Dense(features=5)\n",
    "\n",
    "@jit\n",
    "def predict(params):\n",
    "  return model.apply({'params': params}, X)\n",
    "\n",
    "@jit\n",
    "def loss_fn(params):\n",
    "  return jnp.mean(jnp.abs(Y - predict(params)))\n",
    "\n",
    "# Initialize the model with random values\n",
    "# use random number generator ('rng') as input\n",
    "# to initialize params based on input shape of 'X'.\n",
    "@jit\n",
    "def init_params(rng):\n",
    "  mlp_variables = model.init({'params': rng}, X)\n",
    "  return mlp_variables['params']\n",
    "\n",
    "# TODO\n",
    "# use the init_params function and \n",
    "# jax.random to initalize random params\n",
    "# using PRNGKey\n",
    "params = None\n",
    "print(\"initial params\", params)\n",
    "\n",
    "# Run SGD.\n",
    "for i in range(50):\n",
    "  # TODO use jax transformations to extract the loss value\n",
    "  # and gradients of the loss with respect to the params\n",
    "  loss, grad = pass\n",
    "  print(i, \"loss = \", loss, \"Yhat = \", predict(params))\n",
    "  lr = 0.03\n",
    "  params = jax.tree_util.tree_map(lambda x, d: x - lr * d, params, grad)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP2iG/ZUvKsGUS/phPkkvLs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
